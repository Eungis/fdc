{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class TextClassificationCollator:\n",
    "    def __init__(self, tokenizer, max_length, with_text=True):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.with_text = with_text\n",
    "\n",
    "    def __call__(self, samples):\n",
    "        texts = [sample[\"text\"] for sample in samples]\n",
    "        labels = [sample[\"label\"] for sample in samples]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=self.max_length,\n",
    "        )\n",
    "\n",
    "        return_value = {\n",
    "            \"input_ids\": encoding[\"input_ids\"],\n",
    "            \"attention_mask\": encoding[\"attention_mask\"],\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "        if self.with_text:\n",
    "            return_value[\"text\"] = texts\n",
    "\n",
    "        return return_value\n",
    "\n",
    "\n",
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])\n",
    "        label = self.labels[item]\n",
    "\n",
    "        return {\n",
    "            \"text\": text,\n",
    "            \"label\": label,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def read_text(fn):\n",
    "    with open(fn, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "        labels, texts = [], []\n",
    "        for line in lines:\n",
    "            if line.strip() != \"\":\n",
    "                # The file should have tab delimited two columns.\n",
    "                # First column indicates label field,\n",
    "                # and second column indicates text field.\n",
    "                label, text = line.strip().split(\"\\t\")\n",
    "                labels += [label]\n",
    "                texts += [text]\n",
    "\n",
    "    return labels, texts\n",
    "\n",
    "\n",
    "def get_loaders(fn, tokenizer, valid_ratio=0.2):\n",
    "    # Get list of labels and list of texts.\n",
    "    labels, texts = read_text(fn)\n",
    "\n",
    "    # Generate label to index map.\n",
    "    unique_labels = list(set(labels))\n",
    "    label_to_index = {}\n",
    "    index_to_label = {}\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        label_to_index[label] = i\n",
    "        index_to_label[i] = label\n",
    "\n",
    "    # Convert label text to integer value.\n",
    "    labels = list(map(label_to_index.get, labels))\n",
    "\n",
    "    train_texts, valid_texts, train_labels, valid_labels = train_test_split(\n",
    "        texts, labels, shuffle=True, test_size=valid_ratio, stratify=labels\n",
    "    )\n",
    "    # Get dataloaders using given tokenizer as collate_fn.\n",
    "    train_loader = DataLoader(\n",
    "        TextClassificationDataset(train_texts, train_labels),\n",
    "        batch_size=16,\n",
    "        shuffle=True,\n",
    "        collate_fn=TextClassificationCollator(tokenizer, max_length=256),\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        TextClassificationDataset(valid_texts, valid_labels),\n",
    "        batch_size=16,\n",
    "        collate_fn=TextClassificationCollator(tokenizer, max_length=256),\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader, index_to_label\n",
    "\n",
    "\n",
    "# Get pretrained tokenizer.\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# Get dataloaders using tokenizer from untokenized corpus.\n",
    "train_loader, valid_loader, index_to_label = get_loaders(\n",
    "    \"./data/media.bert.train.tsv\", tokenizer, valid_ratio=0.2\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"|train| =\",\n",
    "    len(train_loader.dataset),\n",
    "    \"|valid| =\",\n",
    "    len(valid_loader.dataset),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9 (main, Dec 15 2022, 10:44:50) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "a10b254881f706e42c635ed13e00f86233c557d346dd26ed90d26c2bb04c756e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
