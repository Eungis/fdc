{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import logging\n",
    "import torch\n",
    "import numpy as np\n",
    "import transformers\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm\n",
    "from argparse import Namespace\n",
    "from transformers import (\n",
    "    MODEL_FOR_QUESTION_ANSWERING_MAPPING,\n",
    "    WEIGHTS_NAME,\n",
    "    AutoConfig,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    squad_convert_examples_to_features,\n",
    ")\n",
    "from transformers.data.metrics.squad_metrics import (\n",
    "    compute_predictions_log_probs,\n",
    "    compute_predictions_logits,\n",
    "    squad_evaluate,\n",
    ")\n",
    "from transformers.data.processors.squad import (\n",
    "    SquadResult,\n",
    "    SquadV1Processor,\n",
    "    SquadV2Processor,\n",
    ")\n",
    "from transformers.trainer_utils import is_main_process\n",
    "\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "except ImportError:\n",
    "    from tensorboardX import SummaryWriter\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_FOR_QUESTION_ANSWERING_MAPPING.keys())\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)\n",
    "\n",
    "\n",
    "def emulate_config():\n",
    "    config = {\n",
    "        \"seed\": 42,\n",
    "        \"n_gpu\": 1,\n",
    "        \"local_rank\": -1,\n",
    "        \"threads\": 8,\n",
    "        # model\n",
    "        \"model_type\": \"electra\",\n",
    "        \"config_name\": \"\",\n",
    "        \"tokenizer_name\": \"\",\n",
    "        \"model_name_or_path\": \"monologg/koelectra-base-v3-discriminator\",\n",
    "        \"doc_stride\": 128,\n",
    "        \"null_score_diff_threshold\": 0,\n",
    "        \"max_seq_length\": 512,\n",
    "        \"max_query_length\": 64,\n",
    "        # train and evaluation\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"evaluate_during_training\": True,\n",
    "        \"do_lower_case\": False,\n",
    "        \"per_gpu_train_batch_size\": 16,\n",
    "        \"per_gpu_eval_batch_size\": 8,\n",
    "        \"learning_rate\": 5e-5,\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"weight_decay\": 0.1,  # L2 Regularization = Weight Decay in terms of SGD, but not the case for Adam.\n",
    "        # cf. Adam vs. AdamW: https://hiddenbeginner.github.io/deeplearning/paperreview/2019/12/29/paper_review_AdamW.html\n",
    "        # cf. LayerNorm vs. BatchNorm: https://velog.io/@glad415/Transformer-7.-%EC%9E%94%EC%B0%A8%EC%97%B0%EA%B2%B0%EA%B3%BC-%EC%B8%B5-%EC%A0%95%EA%B7%9C%ED%99%94-by-WikiDocs\n",
    "        \"adam_epsilon\": 1e-8,\n",
    "        \"max_grad_norm\": 1.0,\n",
    "        \"num_train_epochs\": 3,\n",
    "        \"max_steps\": -1,\n",
    "        \"warmup_steps\": 0,\n",
    "        \"n_best_size\": 20,\n",
    "        \"max_answer_length\": 30,\n",
    "        \"fp16\": False,\n",
    "        \"fp16_opt_level\": \"O1\",  # fp16 level\n",
    "        # logging\n",
    "        \"verbose_logging\": True,  # verbose related to the data processing\n",
    "        \"logging_steps\": 1000,\n",
    "        \"save_steps\": 1000,\n",
    "        \"eval_all_checkpoints\": True,\n",
    "        \"no_cuda\": True,\n",
    "        \"use_mps\": True,  #\n",
    "        \"overwrite_output_dir\": False,\n",
    "        \"overwrite_cache\": False,\n",
    "        # data directory\n",
    "        \"output_dir\": \"koelectra-base-v3-korquad\",\n",
    "        \"data_dir\": \"../data\",\n",
    "        \"train_file\": \"KorQuAD_v1.0_train.json\",\n",
    "        \"predict_file\": \"KorQuAD_v1.0_train.json\",\n",
    "        \"cache_dir\": \"\",\n",
    "        \"version_2_with_negative\": False,\n",
    "    }\n",
    "    config = Namespace(**config)\n",
    "\n",
    "    if config.doc_stride >= config.max_seq_length - config.max_query_length:\n",
    "        logger.warning(\n",
    "            \"WARNING - You've set a doc stride which may be superior to the document length in some \"\n",
    "            \"examples. This could result in errors when building features from the examples. Please reduce the doc \"\n",
    "            \"stride or increase the maximum length to ensure the features are correctly built.\"\n",
    "        )\n",
    "\n",
    "    if (\n",
    "        os.path.exists(config.output_dir)\n",
    "        and os.listdir(config.output_dir)\n",
    "        and config.do_train\n",
    "        and not config.overwrite_output_dir\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n",
    "                config.output_dir\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # setup GPU & distributed learning\n",
    "    if config.local_rank == -1 or config.no_cuda:\n",
    "        if config.use_mps:\n",
    "            device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "        else:\n",
    "            device = torch.device(\n",
    "                \"cuda\" if torch.cuda.is_available() and not config.no_cuda else \"cpu\"\n",
    "            )\n",
    "    else:\n",
    "        # initializes the distributed backend which will take care of synchronizing nodes/GPUs\n",
    "        # only cuda is available in this case\n",
    "        if not torch.cuda.is_available():\n",
    "            raise ValueError(\n",
    "                \"CUDA is not available on this device. Set local_rank to -1 to disable the cuda usage.\"\n",
    "            )\n",
    "        else:\n",
    "            torch.cuda.set_device(config.local_rank)\n",
    "            device = torch.device(\"cuda\", config.local_rank)\n",
    "            torch.distributed.init_process_group(backend=\"nccl\")\n",
    "            config.ngpu = 1\n",
    "\n",
    "    config.device = device\n",
    "\n",
    "    logger.warning(\n",
    "        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
    "        config.local_rank,\n",
    "        device,\n",
    "        config.n_gpu,\n",
    "        bool(config.local_rank != -1),\n",
    "        config.fp16,\n",
    "    )\n",
    "\n",
    "    # Set the verbosity to info of the Transformers logger (on main process only):\n",
    "    if is_main_process(config.local_rank):\n",
    "        transformers.utils.logging.set_verbosity_info()\n",
    "        transformers.utils.logging.enable_default_handler()\n",
    "        transformers.utils.logging.enable_explicit_format()\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def set_seed(config):\n",
    "    # refer to randomness settings in pytorch:\n",
    "    # https://pytorch.org/docs/stable/notes/randomness.html\n",
    "\n",
    "    random.seed(config.seed)\n",
    "    np.random.seed(config.seed)\n",
    "    torch.manual_seed(config.seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(config.seed)\n",
    "\n",
    "    if config.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(config.seed)\n",
    "\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "config = emulate_config()\n",
    "set_seed(config)\n",
    "\n",
    "# Load pretrained model and tokenizer\n",
    "if config.local_rank not in [-1, 0]:\n",
    "    # make sure only the first process in distributed training will download model & vocab\n",
    "    torch.distributed.barrier()\n",
    "\n",
    "config.model_type = config.model_type.lower()\n",
    "model_config = AutoConfig.from_pretrained(\n",
    "    config.config_name if config.config_name else config.model_name_or_path,\n",
    "    cache_dir=config.cache_dir if config.cache_dir else None,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    config.tokenizer_name if config.tokenizer_name else config.model_name_or_path,\n",
    "    do_lower_case=config.do_lower_case,\n",
    "    cache_dir=config.cache_dir if config.cache_dir else None,\n",
    "    use_fast=False,  # SquadDataset is not compatible with Fast tokenizers which have a smarter overflow handeling\n",
    ")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "    config.model_name_or_path,\n",
    "    from_tf=bool(\".ckpt\" in config.model_name_or_path),\n",
    "    config=model_config,\n",
    "    cache_dir=config.cache_dir if config.cache_dir else None,\n",
    ")\n",
    "\n",
    "if config.local_rank == 0:\n",
    "    # make sure only the first process in distributed training will download model & vocab\n",
    "    torch.distributed.barrier()\n",
    "\n",
    "model.to(config.device)\n",
    "logger.info(\"Training/evaluation parameters %s\", config)\n",
    "\n",
    "# Before we do anything with models, we want to ensure that we get fp16 execution of torch.einsum if args.fp16 is set.\n",
    "# Otherwise it'll default to \"promote\" mode, and we'll get fp32 operations. Note that running `--fp16_opt_level=\"O2\"` will\n",
    "# remove the need for this code, but it is still valid.\n",
    "if config.fp16:\n",
    "    try:\n",
    "        import apex\n",
    "\n",
    "        apex.amp.register_half_function(torch, \"einsum\")\n",
    "    except ImportError:\n",
    "        raise ImportError(\n",
    "            \"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_cache_example(config, tokenizer, evaluate=False, output_examples=False):\n",
    "    if config.local_rank not in [-1, 0] and not evaluate:\n",
    "        torch.distributed.barrier()\n",
    "\n",
    "    # load data features from cache or dateset file\n",
    "    input_dir = config.data_dir if config.data_dir else \".\"\n",
    "    cached_features_file = os.path.join(\n",
    "        input_dir,\n",
    "        \"cached_{}_{}_{}\".format(\n",
    "            \"dev\" if evaluate else \"train\",\n",
    "            list(filter(None, config.model_name_or_path.split(\"/\"))).pop(),\n",
    "            str(config.max_seq_length),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # init features and dataset from cache if it exists\n",
    "    if os.path.exists(cached_features_file) and not config.overwrite_cache:\n",
    "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
    "        features_and_dataset = torch.load(cached_features_file)\n",
    "        features, dataset, examples = (\n",
    "            features_and_dataset[\"features\"],\n",
    "            features_and_dataset[\"dataset\"],\n",
    "            features_and_dataset[\"examples\"],\n",
    "        )\n",
    "    else:\n",
    "        logger.info(\"Creating features from dataset file at %s\", input_dir)\n",
    "\n",
    "        if not config.data_dir and (\n",
    "            (evaluate and not config.predict_file)\n",
    "            or (not evaluate and not config.train_file)\n",
    "        ):\n",
    "            try:\n",
    "                import tensorflow_datasets as tfds\n",
    "            except ImportError:\n",
    "                raise ImportError(\n",
    "                    \"If not data_dir is specified, tensorflow_datasets needs to be installed.\"\n",
    "                )\n",
    "\n",
    "            if config.version_2_with_negative:\n",
    "                logger.warning(\n",
    "                    \"tensorflow_datasets does not handle version 2 of SQuAD.\"\n",
    "                )\n",
    "\n",
    "            tfds_examples = tfds.load(\"squad\")\n",
    "            examples = SquadV1Processor().get_examples_from_dataset(\n",
    "                tfds_examples, evaluate=evaluate\n",
    "            )\n",
    "        else:\n",
    "            processor = (\n",
    "                SquadV2Processor()\n",
    "                if config.version_2_with_negative\n",
    "                else SquadV1Processor()\n",
    "            )\n",
    "            if evaluate:\n",
    "                examples = processor.get_dev_examples(\n",
    "                    config.data_dir, filename=config.predict_file\n",
    "                )\n",
    "            else:\n",
    "                examples = processor.get_train_examples(\n",
    "                    config.data_dir, filename=config.train_file\n",
    "                )\n",
    "\n",
    "        features, dataset = squad_convert_examples_to_features(\n",
    "            examples=examples,\n",
    "            tokenizer=tokenizer,\n",
    "            max_seq_length=config.max_seq_length,\n",
    "            doc_stride=config.doc_stride,\n",
    "            max_query_length=config.max_query_length,\n",
    "            is_training=not evaluate,\n",
    "            return_dataset=\"pt\",\n",
    "            threads=config.threads,\n",
    "        )\n",
    "\n",
    "        if config.local_rank in [-1, 0]:\n",
    "            logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
    "            torch.save(\n",
    "                {\"features\": features, \"dataset\": dataset, \"examples\": examples},\n",
    "                cached_features_file,\n",
    "            )\n",
    "\n",
    "    if config.local_rank == 0 and not evaluate:\n",
    "        torch.distributed.barrier()\n",
    "\n",
    "    if output_examples:\n",
    "        return dataset, examples, features\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/30/2024 03:32:42 - INFO - __main__ - Loading features from cached file ../data/cached_train_koelectra-base-v3-discriminator_512\n"
     ]
    }
   ],
   "source": [
    "dataset, examples, features = load_and_cache_example(\n",
    "    config, tokenizer, evaluate=False, output_examples=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"input_ids\": batch[0].unsqueeze(0),\n",
    "    \"attention_mask\": batch[1].unsqueeze(0),\n",
    "    \"token_type_ids\": batch[2].unsqueeze(0),\n",
    "    \"start_positions\": batch[3].unsqueeze(0),\n",
    "    \"end_positions\": batch[4].unsqueeze(0),\n",
    "}\n",
    "\n",
    "for k, v in inputs.items():\n",
    "    inputs[k] = v.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "question: 바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?\n",
      "context: 1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 걲은 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡(1악장)을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다.\n",
      "answer: 교향곡\n",
      "encoded inputs: [2, 29064, 4034, 28889, 4234, 14623, 6334, 4110, 3244, 4219, 6570, 4292, 3063, 4219, 4195, 3771, 4034, 4070, 35, 3, 16095, 4272, 4556, 29064, 4034, 28889, 4234, 14623, 6334, 4292, 6396, 3244, 4219, 2126, 6434, 4073, 6365, 4007, 11666, 3240, 4110, 7402, 4239, 6293, 6272, 4234, 21238, 4292, 3063, 4228, 4034, 2513, 4292, 2022, 4034, 4176, 18, 3240, 6964, 29064, 4034, 16095, 4193, 4556, 4073, 2827, 26774, 10749, 23207, 4141, 4068, 4292, 2348, 1, 6313, 4007, 4118, 11906, 4047, 9837, 4073, 7777, 4398, 6460, 2662, 8463, 4348, 4943, 6944, 4110, 6654, 4034, 14623, 6334, 4234, 19833, 4073, 8345, 4398, 7218, 6217, 18, 6380, 8436, 4073, 4129, 33009, 4116, 4266, 4234, 8228, 4239, 8436, 6836, 4005, 24572, 21319, 4007, 8211, 4279, 4034, 21073, 4234, 21238, 29, 4467, 4292, 2440, 4219, 2146, 4112, 26974, 4292, 2734, 4494, 18781, 16, 6594, 4007, 12208, 21, 4501, 4073, 14623, 6334, 4234, 2914, 4559, 10749, 26425, 3240, 6588, 4073, 6681, 4007, 8518, 6542, 4292, 21070, 24642, 30524, 2048, 4112, 7848, 4519, 9499, 4070, 3123, 4176, 18, 6421, 4234, 2523, 4071, 4084, 6994, 4234, 6245, 8532, 2126, 4234, 7116, 4073, 12950, 3249, 4034, 2048, 11318, 7194, 4283, 6702, 4199, 10440, 4065, 11616, 4070, 7236, 4880, 2048, 4007, 6231, 4118, 21073, 4234, 13894, 4290, 4160, 4559, 6994, 4234, 6542, 4292, 2734, 4112, 2048, 4292, 2784, 2967, 3249, 4176, 18, 20702, 21238, 10062, 4292, 16095, 4272, 4556, 6406, 6625, 4556, 4073, 7975, 8436, 4073, 4129, 10241, 4398, 6742, 21, 4414, 4048, 4292, 3065, 2430, 4073, 7360, 4398, 4176, 18, 6380, 6588, 4234, 7679, 4047, 6843, 4073, 2126, 4034, 3240, 2914, 4559, 12, 21, 4414, 4048, 13, 3232, 8436, 6836, 4005, 4234, 21709, 4073, 4129, 8211, 4519, 8434, 4275, 4149, 4200, 6513, 4279, 4737, 6742, 16, 6989, 4034, 9301, 4200, 4034, 3083, 4494, 4176, 18, 6546, 18677, 4112, 24, 4556, 2733, 4007, 6232, 3826, 4073, 11485, 4422, 4073, 4129, 8211, 4479, 4480, 4219, 19851, 4086, 6714, 8796, 17164, 16, 6298, 4073, 6907, 10660, 4479, 4219, 2633, 4494, 4176, 18, 2126, 6314, 4073, 2126, 4034, 2620, 4137, 4332, 4192, 18531, 4279, 4034, 10178, 4139, 4292, 7679, 4279, 4219, 3598, 4029, 4007, 4394, 8532, 10241, 4279, 4034, 2446, 16145, 4283, 6251, 4292, 8221, 18781, 16, 6269, 12474, 6482, 4007, 3240, 2076, 4292, 3251, 4325, 3757, 2048, 4007, 8181, 3755, 4034, 6740, 4086, 3249, 4176, 18, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "decoded inputs: [CLS] 바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가? [SEP] 1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 [UNK] 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡 ( 1악장 ) 을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "length of tokenized tokens: 512\n",
      "attention masks: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "-> [CLS] 바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가? [SEP]\n",
      "-> 1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 [UNK] 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡 ( 1악장 ) 을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다. [SEP]\n",
      "-> [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "start positions: 46\n",
      "end positions: 46\n",
      "answer: 교향곡\n",
      "class index: 0\n",
      "p_mask: [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "is_impossible: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# squad dataset analysis\n",
    "\n",
    "start_idx, end_idx = 0, 0\n",
    "for idx, type_id in enumerate(batch[2]):\n",
    "    if type_id == 1:\n",
    "        start_idx = idx\n",
    "        break\n",
    "\n",
    "type_ids = batch[2][start_idx:]\n",
    "for idx, type_id in enumerate(type_ids):\n",
    "    if type_id == 0:\n",
    "        end_idx = start_idx + idx\n",
    "        break\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "question: {examples[0].__dict__[\"question_text\"]}\n",
    "context: {examples[0].__dict__[\"context_text\"]}\n",
    "answer: {examples[0].__dict__[\"answer_text\"]}\n",
    "encoded inputs: {batch[0].tolist()}\n",
    "decoded inputs: {tokenizer.decode(batch[0])}\n",
    "length of tokenized tokens: {len(batch[0])}\n",
    "attention masks: {batch[1].tolist()}\n",
    "token_type_ids: {batch[2].tolist()}\n",
    "-> {tokenizer.decode(batch[0][:start_idx])}\n",
    "-> {tokenizer.decode(batch[0][start_idx:end_idx])}\n",
    "-> {tokenizer.decode(batch[0][end_idx:])}\n",
    "start positions: {batch[3]}\n",
    "end positions: {batch[4]}\n",
    "answer: {tokenizer.decode(batch[0][batch[3]: batch[4]+1 if batch[3] == batch[4] else batch[4]])}\n",
    "class index: {batch[5]}\n",
    "p_mask: {batch[6].long().tolist()}\n",
    "is_impossible: {batch[7].long().tolist()}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset, features, examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "# Bias terms are often excluded from weight decay to prevent the model from becoming overly regularized.\n",
    "# LayerNorm weights are often excluded because they are scale and shift parameters that do not benefit from weight decay.\n",
    "optimizer_grouped_parameters = [\n",
    "    # separate parameter groups to apply different weight decay\n",
    "    {\n",
    "        \"params\": [\n",
    "            p\n",
    "            for n, p in model.named_parameters()\n",
    "            if not any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": config.weight_decay,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "optimizer = torch.optim.AdamW(\n",
    "    optimizer_grouped_parameters, lr=config.learning_rate, eps=config.adam_epsilon\n",
    ")\n",
    "# scheduler lr = initial_lr + (max_lr - initial_lr) * (1 - progress) / max(1, (num_training_steps - num_warmup_steps - step))\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=config.warmup_steps, num_training_steps=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config, train_dataset, model, tokenizer):\n",
    "    from tqdm import tqdm, trange\n",
    "\n",
    "    if config.local_rank in [-1, 0]:\n",
    "        tb_writer = SummaryWriter()\n",
    "\n",
    "    config.train_batch_size = config.per_gpu_train_batch_size * max(1, config.n_gpu)\n",
    "    train_sampler = (\n",
    "        RandomSampler(train_dataset)\n",
    "        if config.local_rank == -1\n",
    "        else DistributedSampler(train_dataset)\n",
    "    )\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, batch_size=config.train_batch_size, sampler=train_sampler\n",
    "    )\n",
    "\n",
    "    if config.max_steps > 0:\n",
    "        t_total = config.max_steps\n",
    "        config.num_train_epochs = (\n",
    "            config.max_steps\n",
    "            // (len(train_dataloader) // config.gradient_accumulation_steps)\n",
    "            + 1\n",
    "        )\n",
    "    else:\n",
    "        t_total = (\n",
    "            len(train_dataloader)\n",
    "            // config.gradient_accumulation_steps\n",
    "            * config.num_train_epochs\n",
    "        )\n",
    "\n",
    "    # prep optimizer and schedular\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    # Bias terms are often excluded from weight decay to prevent the model from becoming overly regularized.\n",
    "    # LayerNorm weights are often excluded because they are scale and shift parameters that do not benefit from weight decay.\n",
    "    optimizer_grouped_parameters = [\n",
    "        # separate parameter groups to apply different weight decay\n",
    "        {\n",
    "            \"params\": [\n",
    "                p\n",
    "                for n, p in model.named_parameters()\n",
    "                if not any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay\": config.weight_decay,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [\n",
    "                p\n",
    "                for n, p in model.named_parameters()\n",
    "                if any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        optimizer_grouped_parameters, lr=config.learning_rate, eps=config.adam_epsilon\n",
    "    )\n",
    "    # scheduler lr = initial_lr + (max_lr - initial_lr) * (1 - progress) / max(1, (num_training_steps - num_warmup_steps - step))\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=config.warmup_steps, num_training_steps=t_total\n",
    "    )\n",
    "\n",
    "    # check if saved optimizer or scheduler states exists\n",
    "    if os.path.isfile(\n",
    "        os.path.join(config.model_name_or_path, \"optimizer.pt\")\n",
    "    ) and os.path.isfile(os.path.join(config.model_name_or_path, \"scheduler.pt\")):\n",
    "        # load optimizer and scheduler states\n",
    "        optimizer.load_state_dict(\n",
    "            torch.load(os.path.join(config.model_name_or_path, \"optimizer.pt\"))\n",
    "        )\n",
    "        scheduler.load_state_dict(\n",
    "            torch.load(os.path.join(config.model_name_or_path, \"scheduler.pt\"))\n",
    "        )\n",
    "\n",
    "    if config.fp16:\n",
    "        try:\n",
    "            from apex import amp\n",
    "        except ImportError:\n",
    "            raise ImportError(\n",
    "                \"Please intall apex from https://www.github.com/nvidia/apex to use fp16 training.\"\n",
    "            )\n",
    "\n",
    "        model, optimizer = amp.initialize()\n",
    "\n",
    "    # multi-gpu training (should be after apex fp16 initialization)\n",
    "    if config.n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # distributed training (should be after apex fp16 initialization)\n",
    "    if config.local_rank != -1:\n",
    "        model = torch.nn.parallel.DistributedDataParallel(\n",
    "            model,\n",
    "            device_ids=[config.local_rank],\n",
    "            output_device=config.local_rank,\n",
    "            find_unused_parameters=True,\n",
    "        )\n",
    "\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
    "    logger.info(\"  Num Epochs = %d\", config.num_train_epochs)\n",
    "    logger.info(\n",
    "        \"  Instantaneous batch size per GPU = %d\", config.per_gpu_train_batch_size\n",
    "    )\n",
    "    logger.info(\n",
    "        \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
    "        config.train_batch_size\n",
    "        * config.gradient_accumulation_steps\n",
    "        * (torch.distributed.get_world_size() if config.local_rank != -1 else 1),\n",
    "    )\n",
    "    logger.info(\n",
    "        \"  Gradient Accumulation steps = %d\", config.gradient_accumulation_steps\n",
    "    )\n",
    "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "\n",
    "    global_step = 1\n",
    "    epochs_trained = 0\n",
    "    steps_trained_in_current_epoch = 0\n",
    "\n",
    "    # check if continuing training from a checkpoint\n",
    "    if os.path.exists(config.model_name_or_path):\n",
    "        try:\n",
    "            # set global_step to global_step of last saved checkpoint from model path\n",
    "            checkpoint_suffix = config.model_name_or_path.split(\"-\")[-1].split(\"/\")[0]\n",
    "            global_step = int(checkpoint_suffix)\n",
    "            # if gradient accumulation is used, 1bs => 1bs*gradient_accumulation_steps\n",
    "            # if num_trained_epochs was trained on 1bs with k gradient_accumulation_steps,\n",
    "            # it equals as k*num_trained_epoches was trained.\n",
    "            epochs_trained = global_step // (\n",
    "                len(train_dataloader) // config.gradient_accumulation_steps\n",
    "            )\n",
    "            steps_trained_in_current_epoch = global_step % (\n",
    "                len(train_dataloader) // config.gradient_accumulation_steps\n",
    "            )\n",
    "\n",
    "            logger.info(\n",
    "                \"  Continuing training from checkpoint, will skip to saved global_step\"\n",
    "            )\n",
    "            logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n",
    "            logger.info(\"  Continuing training from global step %d\", global_step)\n",
    "            logger.info(\n",
    "                \"  Will skip the first %d steps in the first epoch\",\n",
    "                steps_trained_in_current_epoch,\n",
    "            )\n",
    "        except ValueError:\n",
    "            logger.info(\"  Starting fine-tuning.\")\n",
    "\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    model.zero_grad()  # similar to optimizer.zero_grad()\n",
    "    train_iterator = trange(\n",
    "        epochs_trained,\n",
    "        int(config.num_train_epochs),\n",
    "        desc=\"Epoch\",\n",
    "        disable=config.local_rank not in [-1, 0],\n",
    "    )\n",
    "\n",
    "    # set random seed\n",
    "    set_seed(config)\n",
    "\n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm(\n",
    "            train_dataloader, desc=\"Iteration\", disable=config.local_rank not in [-1, 0]\n",
    "        )\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            # skip already trained steps if resuming training\n",
    "            if steps_trained_in_current_epoch > 0:\n",
    "                steps_trained_in_current_epoch -= 1\n",
    "                continue\n",
    "\n",
    "            model.train()\n",
    "            # load input_ids, attention_mask, token_type_ids, start_positions and end_positions to gpu\n",
    "            batch = tuple(t.to(config.device) for t in batch)\n",
    "\n",
    "            inputs = {\n",
    "                \"input_ids\": batch[0],\n",
    "                \"attention_mask\": batch[1],\n",
    "                \"token_type_ids\": batch[2],\n",
    "                \"start_positions\": batch[3],\n",
    "                \"end_positions\": batch[4],\n",
    "            }\n",
    "\n",
    "            if config.model_type in [\n",
    "                \"xlm\",\n",
    "                \"roberta\",\n",
    "                \"distilbert\",\n",
    "                \"camembert\",\n",
    "                \"bart\",\n",
    "                \"longformer\",\n",
    "            ]:\n",
    "                del inputs[\"token_type_ids\"]\n",
    "\n",
    "            if config.model_type in [\"xlnet\", \"xlm\"]:\n",
    "                inputs.update({\"cls_index\": batch[5], \"p_mask\": batch[6]})\n",
    "                if config.version_2_with_negative:\n",
    "                    inputs.update({\"is_impossible\": batch[7]})\n",
    "                if hasattr(model, \"config\") and hasattr(model.config, \"lang2id\"):\n",
    "                    inputs.update(\n",
    "                        {\n",
    "                            \"langs\": (\n",
    "                                torch.ones(batch[0].shape, dtypes=torch.int64)\n",
    "                                * config.lang_id\n",
    "                            ).to(config.device)\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "            # forward\n",
    "            outputs = model(**inputs)  # type(outputs): QuestionAnsweringModelOutput\n",
    "            loss = outputs[0]  # to_tuple method of QuestionAnsweringModelOutput\n",
    "\n",
    "            if config.n_gpu > 1:\n",
    "                loss = (\n",
    "                    loss.mean()\n",
    "                )  # mean() to average on multi-gpu parallel (not distributed) training\n",
    "            if config.gradient_accumulation_steps > 1:\n",
    "                loss = loss / config.gradient_accumulation_steps\n",
    "\n",
    "            if config.fp16:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            if (step + 1) % config.gradient_accumulation_steps == 0:\n",
    "                if config.fp16:\n",
    "                    torch.nn.utils.clip_grad_norm_(\n",
    "                        amp.master_params(optimizer), config.max_grad_norm\n",
    "                    )\n",
    "                else:\n",
    "                    torch.nn.utils.clip_grad_norm_(\n",
    "                        model.parameters(), config.max_grad_norm\n",
    "                    )\n",
    "\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                model.zero_grad()\n",
    "                global_step += 1  # increase only when gradient is updated\n",
    "\n",
    "                # log metrics\n",
    "                if (\n",
    "                    config.local_rank in [-1, 0]\n",
    "                    and config.logging_steps > 0\n",
    "                    and global_step % config.logging_steps == 0\n",
    "                ):\n",
    "                    # evaluate only train with single gpu otherwise metrics may not average well\n",
    "                    if config.local_rank == -1 and config.evaluate_during_training:\n",
    "                        results = evaluate(config, model, tokenizer)\n",
    "                        for k, v in results.items():\n",
    "                            tb_writer.add_scalar(\"eval_{}\".format(k), v, global_step)\n",
    "                    tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)\n",
    "                    tb_writer.add_scalar(\n",
    "                        \"loss\",\n",
    "                        (tr_loss - logging_loss) / config.logging_steps,\n",
    "                        global_step,\n",
    "                    )\n",
    "                    logging_loss = tr_loss\n",
    "\n",
    "                # save model checkpoints\n",
    "                if (\n",
    "                    config.local_rank in [-1, 0]\n",
    "                    and config.save_steps > 0\n",
    "                    and global_step % config.save_steps == 0\n",
    "                ):\n",
    "                    output_dir = os.path.join(\n",
    "                        config.output_dir, \"checkpoint-{}\".format(global_step)\n",
    "                    )\n",
    "                    # take care of distributed/parallel training\n",
    "                    model_to_save = model.module if hasattr(model, \"module\") else model\n",
    "                    model_to_save.save_pretrained(\n",
    "                        output_dir\n",
    "                    )  # to use from_pretrained to load model later\n",
    "                    tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "                    torch.save(config, os.path.join(output_dir, \"training_args.bin\"))\n",
    "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
    "\n",
    "                    torch.save(\n",
    "                        optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\")\n",
    "                    )\n",
    "                    torch.save(\n",
    "                        scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\")\n",
    "                    )\n",
    "                    logger.info(\n",
    "                        \"Saving optimizer and scheduler states to %s\", output_dir\n",
    "                    )\n",
    "\n",
    "            if config.max_steps > 0 and global_step > config.max_step:\n",
    "                epoch_iterator.close()\n",
    "                break\n",
    "\n",
    "        if config.max_steps > 0 and global_step > config.max_steps:\n",
    "            train_iterator.close()\n",
    "            break\n",
    "\n",
    "    if config.local_rank in [-1, 0]:\n",
    "        tb_writer.close()\n",
    "\n",
    "    return global_step, tr_loss / global_step\n",
    "\n",
    "\n",
    "def evaluate(config, model, tokenizer):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.do_train:\n",
    "    train_dataset = load_and_cache_example(\n",
    "        config, tokenizer, evaluate=False, output_examples=False\n",
    "    )\n",
    "    global_step, tr_loss = train(config, train_dataset, model, tokenizer)\n",
    "    logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
