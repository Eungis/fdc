{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output parsers \n",
    "- classes that help structure language model responses. There are two main methods an output parser must implement:\n",
    "\n",
    "1. `Get format instructions`: A method which returns a string containing instructions for how the output of a language model should be formatted.\n",
    "2. `Parse`: A method which takes in a string (assumed to be the response from a language model) and parses it into some structure.\n",
    "\n",
    "\n",
    "- Output parsers implement the Runnable interface, the basic building block of the LangChain Expression Language (LCEL). This means they support `invoke`, `ainvoke`, `stream`, `astream`, `batch`, `abatch`, `astream_log` calls.\n",
    "- Output parsers accept a `string` or `BaseMessage` as input and can return an arbitrary type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actor(name='Tom Hanks', film_names=['Forrest Gump'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Actor(BaseModel):\n",
    "    name: str = Field(description=\"name of an actor\")\n",
    "    film_names: List[str] = Field(description=\"list of names of films they starred in\")\n",
    "\n",
    "actor_query = \"Generate the filmography for a random actor.\"\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Actor)\n",
    "misformatted = \"{'name': 'Tom Hanks', 'film_names': ['Forrest Gump']}\"\n",
    "# parser.parse(misformatted) # >> OutputParserException\n",
    "\n",
    "from langchain.output_parsers import OutputFixingParser\n",
    "new_parser = OutputFixingParser.from_llm(\n",
    "    parser=parser,\n",
    "    llm=ChatOpenAI()\n",
    ")\n",
    "new_parser.parse(misformatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action='search' action_input='input_value'\n",
      "action='search' action_input='who is leo di caprios gf?'\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import (\n",
    "    PydanticOutputParser,\n",
    "    OutputFixingParser,\n",
    "    RetryOutputParser,\n",
    ")\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List\n",
    "from langchain.output_parsers import RetryWithErrorOutputParser\n",
    "\n",
    "template = \"\"\"Based on the user question, provide an Action and Action Input for what step should be taken.\n",
    "{format_instructions}\n",
    "Question: {query}\n",
    "Response:\"\"\"\n",
    "\n",
    "\n",
    "class Action(BaseModel):\n",
    "    action: str = Field(description=\"action to take\")\n",
    "    action_input: str = Field(description=\"input to the action\")\n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Action)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "prompt_value = prompt.format_prompt(query=\"who is leo di caprios gf?\")\n",
    "bad_response = '{\"action\": \"search\"}'\n",
    "# parser.parse(bad_response) # > OutputParserException\n",
    "\n",
    "# Using OutputFixingParser cannot resolve it, as it doesn't know what to put in action_input.\n",
    "fix_parser = OutputFixingParser.from_llm(parser=parser, llm=ChatOpenAI())\n",
    "print(fix_parser.parse(bad_response))\n",
    "\n",
    "# Use retryparser to resolve it\n",
    "from langchain.output_parsers import RetryWithErrorOutputParser\n",
    "retry_parser = RetryWithErrorOutputParser.from_llm(\n",
    "    parser=parser, llm=OpenAI(temperature=0)\n",
    ")\n",
    "print(retry_parser.parse_with_prompt(bad_response, prompt_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<movie>Big</movie><movie>Forrest Gump</movie><movie>Saving Private Ryan</movie><movie>Cast Away</movie><movie>The Green Mile</movie><movie>Toy Story</movie><movie>A League of Their Own</movie><movie>Apollo 13</movie><movie>The Da Vinci Code</movie><movie>Sully</movie>\n",
      "{'movies': [{'actor': [{'name': 'Tom Hanks'}, {'film': [{'name': 'Forrest Gump'}, {'genre': 'Drama'}]}, {'film': [{'name': 'Cast Away'}, {'genre': 'Adventure'}]}, {'film': [{'name': 'Saving Private Ryan'}, {'genre': 'War'}]}]}]}\n"
     ]
    }
   ],
   "source": [
    "## XMLOutputParser\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import XMLOutputParser\n",
    "\n",
    "model = OpenAI()\n",
    "actor_query = \"Generate the shortened filmography for Tom Hanks.\"\n",
    "template = f\"\"\"\n",
    "\n",
    "Human:\n",
    "{actor_query}\n",
    "Please enclose the movies in <movie></movie> tags\n",
    "Assistant:\n",
    "\"\"\"\n",
    "output = model(template.format(actor_query=actor_query))\n",
    "print(output)\n",
    "\n",
    "parser = XMLOutputParser(tags=[\"movies\", \"actor\", \"film\", \"name\", \"genre\"])\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    \n",
    "    Human:\n",
    "    {query}\n",
    "    {format_instructions}\n",
    "    AI:\"\"\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "output = chain.invoke({\"query\": actor_query})\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
