{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StuffDocumentsChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import StuffDocumentsChain, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# This controls how each document will be formatted. Specifically,\n",
    "# it will be passed to `format_document` - see that function for more\n",
    "# details.\n",
    "document_prompt = PromptTemplate.from_template(\"Page {page}\\n{page_content}\")\n",
    "document_variable_name = \"context\"\n",
    "llm = OpenAI()\n",
    "# The prompt here should take as an input variable the\n",
    "# `document_variable_name`\n",
    "prompt = PromptTemplate.from_template(\"Summarize this content: {context}\")\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "chain = StuffDocumentsChain(\n",
    "    llm_chain=llm_chain,\n",
    "    document_prompt=document_prompt,\n",
    "    document_variable_name=document_variable_name,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate langchain Document with dummy text.\n",
    "with open(\"../data/state_of_the_union.txt\", \"r\") as f:\n",
    "    DUMMY_TXT = \"\"\n",
    "    for line in f.readlines():\n",
    "        if line.strip() != \"\":\n",
    "            DUMMY_TXT += line\n",
    "\n",
    "import numpy as np\n",
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "def lc_doc_generator(n, txt, ws=2000):\n",
    "    cnt, start, end = 0, 0, ws\n",
    "    doc_size = len(txt)\n",
    "\n",
    "    while (cnt < n) and (start <= doc_size):\n",
    "        doc = Document(page_content=txt[start:end], metadata={\"page\": cnt})\n",
    "        cnt += 1\n",
    "        start = end\n",
    "        end += ws\n",
    "        yield doc\n",
    "\n",
    "\n",
    "lc_doc_generator = lc_doc_generator(n=np.inf, txt=DUMMY_TXT)\n",
    "docs = [doc for doc in lc_doc_generator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## --------------------- ##\n",
      "['input_documents']\n",
      "Page 0\n",
      "Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \n",
      "Last year COVID-19 kept us apart. This year we are finally together again. \n",
      "Tonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \n",
      "With a duty to one another to the American people to the Constitution. \n",
      "And with an unwavering resolve that freedom will always triumph over tyranny. \n",
      "Six days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \n",
      "He thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \n",
      "He met the Ukrainian people. \n",
      "From President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world. \n",
      "Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland. \n",
      "In this struggle as President Zelenskyy said in his speech to the European Parliament “Light will win over darkness.” The Ukrainian Ambassador to the United States is here tonight. \n",
      "Let each of us here tonight in this Chamber send an unmistakable signal to Ukraine and to the world. \n",
      "Please rise if you are able and show that, Yes, we the United States of America stand with the Ukrainian people. \n",
      "Throughout our history we’ve learned this lesson when dictators do not pay a price for their aggression they cause more chaos.   \n",
      "They keep moving.   \n",
      "And the costs and the threats to America and the world keep rising.   \n",
      "That’s why the NATO Alliance was created to secure peace and stability in Europe after World War 2. \n",
      "The United States is a member along with 29 other nations. \n",
      "It matters. American diplomacy matters. American resolve matters. \n",
      "Putin’s latest attack on Ukraine was premeditated and unprovoked. \n",
      "He rejected \n",
      "## --------------------- ##\n",
      "Keys: dict_keys(['context'])\n",
      "\n",
      "Page 0\n",
      "Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \n",
      "Last year COVID-19 kept us apart. This year we are finally together again. \n",
      "Tonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \n",
      "With a duty to one another to the American people to the Constitution. \n",
      "And with an unwavering resolve that freedom will always triumph over tyranny. \n",
      "Six days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \n",
      "He thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \n",
      "He met the Ukrainian people. \n",
      "From President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world. \n",
      "Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland. \n",
      "In this struggle as President Zelenskyy said in his speech to the European Parliament “Light will win over darkness.” The Ukrainian Ambassador to the United States is here tonight. \n",
      "Let each of us here tonight in this Chamber send an unmistakable signal to Ukraine and to the world. \n",
      "Please rise if you are able and show that, Yes, we the United States of America stand with the Ukrainian people. \n",
      "Throughout our history we’ve learned this lesson when dictators do not pay a price for their aggression they cause more chaos.   \n",
      "They keep moving.   \n",
      "And the costs and the threats to America and the world keep rising.   \n",
      "That’s why the NATO Alliance was created to secure peace and stability in Europe after World War 2. \n",
      "The United States is a member along with 29 other nations. \n",
      "It matters. American diplomacy matters. American resolve matters. \n",
      "Putin’s latest attack on Ukraine was premeditated and unprovoked. \n",
      "He rejected \n",
      "\n",
      "Page 1\n",
      "repeated efforts at diplomacy. \n",
      "He thought the West and NATO wouldn’t respond. And he thought he could divide us at home. Putin was wrong. We were ready.  Here is what we did.   \n",
      "We prepared extensively and carefully. \n",
      "We spent months building a coalition of other freedom-loving nations from Europe and the Americas to Asia and Africa to confront Putin. \n",
      "I spent countless hours unifying our European allies. We shared with the world in advance what we knew Putin was planning and precisely how he would try to falsely justify his aggression.  \n",
      "We countered Russia’s lies with truth.   \n",
      "And now that he has acted the free world is holding him accountable. \n",
      "Along with twenty-seven members of the European Union including France, Germany, Italy, as well as countries like the United Kingdom, Canada, Japan, Korea, Australia, New Zealand, and many others, even Switzerland. \n",
      "We are inflicting pain on Russia and supporting the people of Ukraine. Putin is now isolated from the world more than ever. \n",
      "Together with our allies –we are right now enforcing powerful economic sanctions. \n",
      "We are cutting off Russia’s largest banks from the international financial system.  \n",
      "Preventing Russia’s central bank from defending the Russian Ruble making Putin’s $630 Billion “war fund” worthless.   \n",
      "We are choking off Russia’s access to technology that will sap its economic strength and weaken its military for years to come.  \n",
      "Tonight I say to the Russian oligarchs and corrupt leaders who have bilked billions of dollars off this violent regime no more. \n",
      "The U.S. Department of Justice is assembling a dedicated task force to go after the crimes of Russian oligarchs.  \n",
      "We are joining with our European allies to find and seize your yachts your luxury apartments your private jets. We are coming for your ill-begotten gains. \n",
      "And tonight I am announcing that we will join our allies in closing off American air space to all Russian flights – further isolating Russia – and adding an additional squeeze –on thei\n",
      "## --------------------- ##\n",
      "['output_text'] ['input_documents']\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "This speech is about the United States of America standing with the Ukrainian people against Russia's aggression. The President outlines the actions taken to hold Russia accountable, such as economic sanctions, preventing the Russian ruble from being defended, cutting off access to technology and announcing a task force to go after the crimes of Russian oligarchs. The speech also states that the U.S. will join other allies in closing off American airspace to all Russian flights.\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Any\n",
    "from langchain.schema import format_document\n",
    "\n",
    "## --------------------- ##\n",
    "## Way that BaseCombineDocumentsChain format documents\n",
    "print(\"## --------------------- ##\")\n",
    "# input_keys of BaseCombineDocumentsChain\n",
    "print(chain.input_keys)\n",
    "\n",
    "doc = docs[0]\n",
    "document_prompt = PromptTemplate.from_template(\"Page {page}\\n{page_content}\")\n",
    "print(format_document(doc, prompt=document_prompt))\n",
    "\n",
    "print(\"## --------------------- ##\")\n",
    "\n",
    "\n",
    "## Way that StuffDocumentChain get inputs and format the final prompt\n",
    "# _get_inputs of StuffDocumentsChain\n",
    "def _get_inputs(chain, docs: List[Document], **kwargs: Any) -> dict:\n",
    "    \"\"\"Construct inputs from kwargs and docs.\n",
    "\n",
    "    Format and the join all the documents together into one input with name\n",
    "    `chain.document_variable_name`. The pluck any additional variables\n",
    "    from **kwargs.\n",
    "\n",
    "    Args:\n",
    "        docs: List of documents to format and then join into single input\n",
    "        **kwargs: additional inputs to chain, will pluck any other required\n",
    "            arguments from here.\n",
    "\n",
    "    Returns:\n",
    "        dictionary of inputs to LLMChain\n",
    "    \"\"\"\n",
    "    # Format each document according to the prompt\n",
    "    doc_strings = [format_document(doc, chain.document_prompt) for doc in docs]\n",
    "    # Join the documents together to put them in the prompt.\n",
    "    inputs = {\n",
    "        k: v for k, v in kwargs.items() if k in chain.llm_chain.prompt.input_variables\n",
    "    }\n",
    "    inputs[chain.document_variable_name] = chain.document_separator.join(doc_strings)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "print(f\"Keys: {_get_inputs(chain, docs).keys()}\", end=\"\\n\\n\")\n",
    "print(_get_inputs(chain, docs)[\"context\"])\n",
    "\n",
    "print(\"## --------------------- ##\")\n",
    "print(chain.output_keys, chain.input_keys)\n",
    "print(chain.run({\"input_documents\": docs}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReduceDocumentsChain\n",
    "\n",
    "- What if `prompt` exceeds the token_max at the final llm_chain?\n",
    "- Set the maximum number of tokens to group documents into. For example, if set to 3000 then documents will be grouped into chunks of no greater than 3000 tokens before trying to combine them into a smaller chunk.\n",
    "    \n",
    "    - `_collapse` & `_split_list_of_docs` provides hints for dealing with the situation.\n",
    "    \n",
    "    - `collapse_documents_chain` is used if the documents passed in are too many to all be passed to `combine_documents_chain` in one go. In this case, `collapse_documents_chain` is called recursively on as big of groups of documents as are allowed.\n",
    "    \n",
    "    - Premise:\n",
    "        - A single `Document` should not exceed the token_max.\n",
    "        - `llm` must be supported by langchain, and has `get_num_tokens` method to count tokens.\n",
    "        - It can be used with `BaseCombineDocumentsChain` - `prompt_length` method.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import StuffDocumentsChain, LLMChain, ReduceDocumentsChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# This controls how each document will be formatted. Specifically,\n",
    "# it will be passed to `format_document` - see that function for more\n",
    "# details.\n",
    "document_prompt = PromptTemplate.from_template(\"Page {page}\\n{page_content}\")\n",
    "document_variable_name = \"context\"\n",
    "llm = OpenAI(temperature=0)\n",
    "# The prompt here should take as an input variable the\n",
    "# `document_variable_name`\n",
    "prompt = PromptTemplate.from_template(\"Summarize this content: {context}\")\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=llm_chain,\n",
    "    document_prompt=document_prompt,\n",
    "    document_variable_name=document_variable_name,\n",
    ")\n",
    "# Version.1: without specifying collapse chain\n",
    "# if no callapse chain, it use combine_documents_chain.\n",
    "chain = ReduceDocumentsChain(\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version.2: with specifying collapse chain\n",
    "prompt = PromptTemplate.from_template(\"Collapse this content: {context}\")\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "collapse_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=llm_chain,\n",
    "    document_prompt=document_prompt,\n",
    "    document_variable_name=document_variable_name,\n",
    ")\n",
    "chain = ReduceDocumentsChain(\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    "    collapse_documents_chain=collapse_documents_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Optional, Any, Tuple, Callable, Protocol\n",
    "from langchain.callbacks.manager import Callbacks\n",
    "\n",
    "\n",
    "def _split_list_of_docs(\n",
    "    docs: List[Document], length_func: Callable, token_max: int, **kwargs: Any\n",
    ") -> List[List[Document]]:\n",
    "    new_result_doc_list = []\n",
    "    _sub_result_docs = []\n",
    "    for doc in docs:\n",
    "        _sub_result_docs.append(doc)\n",
    "        _num_tokens = length_func(_sub_result_docs, **kwargs)\n",
    "        if _num_tokens > token_max:\n",
    "            if len(_sub_result_docs) == 1:\n",
    "                raise ValueError(\n",
    "                    \"A single document was longer than the context length,\"\n",
    "                    \" we cannot handle this.\"\n",
    "                )\n",
    "            new_result_doc_list.append(_sub_result_docs[:-1])\n",
    "            _sub_result_docs = _sub_result_docs[-1:]\n",
    "    new_result_doc_list.append(_sub_result_docs)\n",
    "    return new_result_doc_list\n",
    "\n",
    "\n",
    "## prepare parameters\n",
    "_docs = docs[-3:]\n",
    "length_func = chain.combine_documents_chain.prompt_length\n",
    "\n",
    "## make use of the token_max of the model as efficiently as possible\n",
    "new_docs = _split_list_of_docs(_docs, length_func, token_max=600)\n",
    "print(len(_docs), len(new_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='ngers. \\nOne was stationed at bases and breathing in toxic smoke from “burn pits” that incinerated wastes of war—medical and hazard material, jet fuel, and more. \\nWhen they came home, many of the world’s fittest and best trained warriors were never the same. \\nHeadaches. Numbness. Dizziness. \\nA cancer that would put them in a flag-draped coffin. \\nI know. \\nOne of those soldiers was my son Major Beau Biden. \\nWe don’t know for sure if a burn pit was the cause of his brain cancer, or the diseases of so many of our troops. \\nBut I’m committed to finding out everything we can. \\nCommitted to military families like Danielle Robinson from Ohio. \\nThe widow of Sergeant First Class Heath Robinson.  \\nHe was born a soldier. Army National Guard. Combat medic in Kosovo and Iraq. \\nStationed near Baghdad, just yards from burn pits the size of football fields. \\nHeath’s widow Danielle is here with us tonight. They loved going to Ohio State football games. He loved building Legos with their daughter. \\nBut cancer from prolonged exposure to burn pits ravaged Heath’s lungs and body. \\nDanielle says Heath was a fighter to the very end. \\nHe didn’t know how to stop fighting, and neither did she. \\nThrough her pain she found purpose to demand we do better. \\nTonight, Danielle—we are. \\nThe VA is pioneering new ways of linking toxic exposures to diseases, already helping more veterans get benefits. \\nAnd tonight, I’m announcing we’re expanding eligibility to veterans suffering from nine respiratory cancers. \\nI’m also calling on Congress: pass a law to make sure veterans devastated by toxic exposures in Iraq and Afghanistan finally get the benefits and comprehensive health care they deserve. \\nAnd fourth, let’s end cancer as we know it. \\nThis is personal to me and Jill, to Kamala, and to so many of you. \\nCancer is the #2 cause of death in America–second only to heart disease. \\nLast month, I announced our plan to supercharge  \\nthe Cancer Moonshot that President Obama asked me to lead six years ago. \\nOur g', metadata={'page': 17})]\n",
      "[Document(page_content='oal is to cut the cancer death rate by at least 50% over the next 25 years, turn more cancers from death sentences into treatable diseases.  \\nMore support for patients and families. \\nTo get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \\nIt’s based on DARPA—the Defense Department project that led to the Internet, GPS, and so much more.  \\nARPA-H will have a singular purpose—to drive breakthroughs in cancer, Alzheimer’s, diabetes, and more. \\nA unity agenda for the nation. \\nWe can do this. \\nMy fellow Americans—tonight , we have gathered in a sacred space—the citadel of our democracy. \\nIn this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things. \\nWe have fought for freedom, expanded liberty, defeated totalitarianism and terror. \\nAnd built the strongest, freest, and most prosperous nation the world has ever known. \\nNow is the hour. \\nOur moment of responsibility. \\nOur test of resolve and conscience, of history itself. \\nIt is in this moment that our character is formed. Our purpose is found. Our future is forged. \\nWell I know this nation.  \\nWe will meet the test. \\nTo protect freedom and liberty, to expand fairness and opportunity. \\nWe will save democracy. \\nAs hard as these times have been, I am more optimistic about America today than I have been my whole life. \\nBecause I see the future that is within our grasp. \\nBecause I know there is simply nothing beyond our capacity. \\nWe are the only nation on Earth that has always turned every crisis we have faced into an opportunity. \\nThe only nation that can be defined by a single word: possibilities. \\nSo on this night, in our 245th year as a nation, I have come to report on the State of the Union. \\nAnd my report is this: the State of the Union is strong—because you, the American people, are strong. \\nWe are stronger today than we were a year ago. \\nAnd we will be stronger a year from now than we are today. \\nNow is our ', metadata={'page': 18}), Document(page_content='moment to meet and overcome the challenges of our time. \\nAnd we will, as one people. \\nOne America. \\nThe United States of America. \\nMay God bless you all. May God protect our troops.', metadata={'page': 19})]\n"
     ]
    }
   ],
   "source": [
    "class CombineDocsProtocol(Protocol):\n",
    "    \"\"\"Interface for the combine_docs method.\"\"\"\n",
    "\n",
    "    def __call__(self, docs: List[Document], **kwargs: Any) -> str:\n",
    "        \"\"\"Interface for the combine_docs method.\"\"\"\n",
    "\n",
    "\n",
    "def _collapse_docs(\n",
    "    docs: List[Document],\n",
    "    combine_document_func: CombineDocsProtocol,\n",
    "    **kwargs: Any,\n",
    ") -> Document:\n",
    "    result = combine_document_func(docs, **kwargs)\n",
    "    combined_metadata = {k: str(v) for k, v in docs[0].metadata.items()}\n",
    "    for doc in docs[1:]:\n",
    "        for k, v in doc.metadata.items():\n",
    "            if k in combined_metadata:\n",
    "                combined_metadata[k] += f\", {v}\"\n",
    "            else:\n",
    "                combined_metadata[k] = str(v)\n",
    "    return Document(page_content=result, metadata=combined_metadata)\n",
    "\n",
    "\n",
    "def _collapse(\n",
    "    chain,\n",
    "    docs: List[Document],\n",
    "    token_max: Optional[int] = None,\n",
    "    callbacks: Callbacks = None,\n",
    "    **kwargs: Any,\n",
    ") -> Tuple[List[Document], dict]:\n",
    "    result_docs = docs\n",
    "    length_func = chain.combine_documents_chain.prompt_length\n",
    "    num_tokens = length_func(result_docs, **kwargs)\n",
    "\n",
    "    def _collapse_docs_func(docs: List[Document], **kwargs: Any) -> str:\n",
    "        return chain._collapse_chain.run(\n",
    "            input_documents=docs, callbacks=callbacks, **kwargs\n",
    "        )\n",
    "\n",
    "    _token_max = token_max or chain.token_max\n",
    "    while num_tokens is not None and num_tokens > _token_max:\n",
    "        new_result_doc_list = _split_list_of_docs(\n",
    "            result_docs, length_func, _token_max, **kwargs\n",
    "        )\n",
    "        result_docs = []\n",
    "        for docs in new_result_doc_list:\n",
    "            print(docs)\n",
    "            new_doc = _collapse_docs(docs, _collapse_docs_func, **kwargs)\n",
    "            result_docs.append(new_doc)\n",
    "        num_tokens = length_func(result_docs, **kwargs)\n",
    "    return result_docs, {}\n",
    "\n",
    "\n",
    "_docs = docs[-3:]\n",
    "new_docs, _ = _collapse(chain, _docs, token_max=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"\\n\\nJoe Biden is discussing the effects of burn pits on military personnel and the story of Danielle Robinson, whose husband Heath was exposed to burn pits. He is calling on Congress to pass a law to provide veterans affected by toxic exposures in Iraq and Afghanistan with the benefits and health care they deserve. He is also announcing a $10 billion commitment to the Cancer Moonshot to end cancer as well as funding for ARPA-H, an Advanced Research Projects Agency for Health, to drive breakthroughs in cancer, Alzheimer's, diabetes, and more. He believes that the United States of America is the only nation that can turn every crisis into an opportunity and that the State of the Union is strong.\",\n",
       " {})"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Finally, put new_docs into the combine_documents_chain\n",
    "chain.combine_documents_chain.combine_docs(docs=new_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MapReduceDocumentsChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import (\n",
    "    StuffDocumentsChain,\n",
    "    LLMChain,\n",
    "    ReduceDocumentsChain,\n",
    "    MapReduceDocumentsChain,\n",
    ")\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# This controls how each document will be formatted. Specifically,\n",
    "# it will be passed to `format_document` - see that function for more\n",
    "# details.\n",
    "document_prompt = PromptTemplate.from_template(\"Page {page}\\n{page_content}\")\n",
    "document_variable_name = \"context\"\n",
    "llm = OpenAI()\n",
    "# The prompt here should take as an input variable the\n",
    "# `document_variable_name`\n",
    "prompt = PromptTemplate.from_template(\"Summarize this content: {context}\")\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "# We now define how to combine these summaries\n",
    "reduce_prompt = PromptTemplate.from_template(\"Combine these summaries: {context}\")\n",
    "reduce_llm_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_llm_chain,\n",
    "    document_prompt=document_prompt,\n",
    "    document_variable_name=document_variable_name,\n",
    ")\n",
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    ")\n",
    "chain = MapReduceDocumentsChain(\n",
    "    llm_chain=llm_chain,\n",
    "    reduce_documents_chain=reduce_documents_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
