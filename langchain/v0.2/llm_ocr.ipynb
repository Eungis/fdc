{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from hydra import compose, initialize\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "with initialize(version_base=None, config_path=\"./config\"):\n",
    "    cfg = compose(config_name=\"properties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from omegaconf import DictConfig\n",
    "from openai import RateLimitError\n",
    "from operator import itemgetter\n",
    "from langchain.chains.base import Chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_openai.chat_models import AzureChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.runnables import RunnableParallel, RunnableSequence, RunnableLambda, RunnablePassthrough, ConfigurableField\n",
    "\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def build_chat_model(cfg: DictConfig):\n",
    "    model = AzureChatOpenAI(\n",
    "        **cfg.llm.openai\n",
    "    ).configurable_alternatives(\n",
    "        ConfigurableField(id=\"llm_type\"),\n",
    "        default_key=\"openai\"\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def format_messages(inputs: dict):\n",
    "    system_message = (\n",
    "        \"You are a helpful AI bot.\" \n",
    "        if not inputs.get(\"system_prompt\") else inputs.get(\"system_prompt\")\n",
    "    )\n",
    "    # format prompt\n",
    "    human_messages = [{\"type\": \"text\", \"text\" : inputs[\"question\"]}]\n",
    "    image_urls = inputs[\"images\"]\n",
    "    for image_url in image_urls:\n",
    "        human_messages += [\n",
    "            {\n",
    "                \"type\" : \"image_url\",\n",
    "                \"image_url\" : {\"url\" : image_url}\n",
    "            }     \n",
    "        ]\n",
    "    return [SystemMessage(content=system_message), HumanMessage(content=human_messages)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ATTEMPT = 3\n",
    "model = build_chat_model(cfg)\n",
    "\n",
    "chain = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            \"system_prompt\": itemgetter(\"system_prompt\"),\n",
    "            \"question\": itemgetter(\"question\"),\n",
    "            \"images\": itemgetter(\"images\") | RunnableLambda(\n",
    "                lambda x: [f\"data:image/jpeg;base64,{encode_image(_)}\" for _ in x]\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    | format_messages\n",
    "    | model.with_retry(\n",
    "        retry_if_exception_type=(RateLimitError,),\n",
    "        stop_after_attempt=MAX_ATTEMPT,\n",
    "        wait_exponential_jitter=True\n",
    "    )\n",
    ")\n",
    "\n",
    "system_prompt = \"\"\"You are an Optical Character Recognition machine.\n",
    "You will extract all the characters from the image provided by the user, and you will only privide the extracted text in your response.\n",
    "As an OCR machine, You can only respond with the extracted text according to the following intruction.\n",
    "* Do not modify any of the content in the given image.\n",
    "* Skip the preamble in your answer.\n",
    "* Format your answer with structurized information such as markdown or html.\n",
    "* Do not translate any of the content in the given image. Return as it is.\"\"\"\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"system_prompt\": system_prompt,\n",
    "        \"question\": \"이미지에 있는 텍스트를 원본 그대로 추출해줘.\",\n",
    "        \"images\": [\"./data/table_2.png\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 은행명 | 상품명 | 금리 | 대상 |\n",
      "| --- | --- | --- | --- |\n",
      "| KB국민은행 | KB무궁화 신용대출 | 1.25 | 경찰청 협약 |\n",
      "|  | KB공무원 우대대출 | 1.99 | 공무원연금공단 협약 |\n",
      "| 신한은행 | 세미래 행복대출 | 1.70 | 국세청 협약 |\n",
      "|  | 서울메이트 공무원대출 | 2.19 | 서울특별시 협약 |\n",
      "| 우리은행 | 공무원 PPL | 2.69 |  |\n",
      "| 하나은행 | 공무원기계차지대출 | 2.21 | 공무원연금공단 협약 |\n",
      "| NH농협은행 | e-채움 공무원기계자금 *공지사항은인터넷뱅킹 상품 | 1.72 | 공무원연금공단 협약 |\n",
      "|  | 공무원생활안정자금 | 1.69 | 공무원연금공단·국군재정관리단 협약 |\n",
      "\n",
      "*2021년 4월 평균금리 기준, 단 NH농협은행은 최저금리 기준 (자료: 김도균 의원실)\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
