{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "data = {\n",
    "    \"title\": \"KE 판매_OAL 운항하는 공동운항편.txt\",\n",
    "    \"context\": '<p>안녕하세요</p>\\n<table>\\n   <tr>\\n    <td>\\n     [공동운항편 예약시 대고객 안내 문구]\\n√ XXXX - 운항사\\n     <table>\\n      <tr>\\n       <td>\\n        1) 대한항공 항공기가 아닌 XXXX로 운항하는 공동운항편 입니다. (아래 가. 항 참조) 2) 공동운항편의 운임은 XXXX에서 구입 시의 운임과 다를 수 있습니다. 3) 공동운항편의 탑승수속은 실제 운항하는 항공사의 터미널과 탑승수속 카운터를 이용하셔야 합니다. 탑승수속 마감시간은\\n운항사 규정에 따라 다를 수 있으니 반드시 운항사로 확인하여 주시기 바랍니다. (아래 나. 항 참조) 4) 공동운항편의 제반 서비스는 항공사별로 상이하며 유/무료 사전좌석배정, 아기바구니, 특별기내식, 좌석승급, 스카이패스\\n 우수회원 혜택, 웹/모바일/키오스크 체크인, 휠체어, 반려동물 동반 등의 서비스가 제공되지 않을 수 있습니다.\\n필요한 부가서비스가 있으신 고객께서는 예약 및 발권을 진행하시기 전에 제공 가능 여부를 확인하여 주시기 바랍니다. (아래 다.항 참조) 5) 운항사의 규정에 따라 만15세 미만의 승객이 성인 보호자 없이 여행하거나, 동반하는 보호자가 만 18세 미만인 경우는\\n 탑승이 제한될 수 있으니 운항사로 확인하여 주시기 바랍니다. (아래 다.항 참조) 6) 수하물은 공동운항 협정에 따라 운항사 또는 판매사의 규정이 적용되므로 사전에 확인하여 주시기 바랍니다. (아래 다.항 참조)\\n       </td>\\n      </tr>\\n     </table>\\n    </td>\\n   </tr>\\n   <tr>\\n    <td>\\n     실제 운항사 고지\\n    </td>\\n   </tr>\\n   <tr>\\n    <td>\\n     ○ 고객이 탑승하게 될 실제 항공사명 안내\\n○ 미국 교통부 (U.S DOT) 규정에 따라 공동운항편 예약시 운항사 고지 의무가 있으며, 운항사의 관계사(DBA:Doing Business As)가 실제 운항편인 경우\\n이에 대한 안내도 해야하므로, 편명 하단에 \"DBA\" 가 표시된 구간 예약시 실제 운항편으로 안내 (관련 화면 보기 ☞ Click Here)\\n     <table>\\n      <tr>\\n       <td>\\n        운항사\\n       </td>\\n       <td>\\n        대상편 표준안내문구\\n       </td>\\n      </tr>\\n      <tr>\\n       <td>\\n        AS\\n       </td>\\n       <td>\\n        AS(ALSKA AIRLINES) 관계사인 QX(Horizon Air) 항공기로 운항하는 공동운항편입니다.\\n       </td>\\n      </tr>\\n      <tr>\\n       <td>\\n        EY\\n       </td>\\n       <td>\\n        EY(ETIHAD AIRWAYS) 관계사인 9W(Jet Airways) 외장을 가진 항공기로 운항하는 공동운항편입니다.\\n       </td>\\n      </tr>\\n      <tr>\\n       <td>\\n        KL\\n       </td>\\n       <td>\\n        KL(KLM-ROYAL DUTCH AIRLINES) 관계사인 WA(KLM Cityhopper) 항공기로 운항하는 공동운항편입니다.\\n       </td>\\n      </tr>\\n      <tr>\\n       <td>\\n        LA\\n       </td>\\n       <td>\\n        LA(LAN AIRLINES) 관계사인 LP(Lan Peru) 항공기로 운항하는 공동운항편입니다.\\n       </td>\\n      </tr>\\n      <tr>\\n       <td>\\n        AR\\n       </td>\\n       <td>\\n        AR(AEROLINEAS ARGENTINAS) 관계사인 AU (Austral Lineas Aereas) 항공기로 운항하는 공동운항편입니다.\\n       </td>\\n      </tr>\\n     </table>\\n     ○ 실제 운항 기재, 승무원 등 운송 및 운항 관련 서비스는 실제 운항사 기준으로 적용됨을 안내\\n    </td>\\n   </tr>\\n   <tr>\\n    <td>\\n     탑승터미널 위치, 탑승수속 마감시간 확인\\n    </td>\\n   </tr>\\n   <tr>\\n    <td>\\n     ○ 탑승 절차 관련하여 탑승 터미널 위치, 탑승 수속 마감시간 및 운항사 카운터 이용 안내\\n - 탑승 터미널 위치\\n: 스케줄 조회화면 또는 편명 더블클릭하여 Flight Schedule 팝업 내 Description 에서 확인 가능\\n- 탑승 수속 마감시간 : 편명 더블클릭하여 Flight Schedule 팝업 내 Description에서 확인 또는 좌석 확보시 팝업에서\\n \" CHKIN CLOSE TIME CHECK WITH OPERATING CARR \" 문구 확인됨\\n[스케줄 조회 화면]\\n [좌석 확보시 팝업]\\n [Flight Schedule 팝업]\\n    </td>\\n   </tr>\\n   <tr>\\n    <td>\\n     Special Service 관련\\n    </td>\\n   </tr>\\n   <tr>\\n    <td>\\n     ○ KE Marketing 승객에게 제공되는 Special Meal 및 Special Service는 기본적으로 운항사의 제공 기준에 따르므로,\\n파트너사별 서비스 제공 여부 및 신청 가능 시점이 상이함\\n따라서, Special Meal 및 Special Service 신청시, 서비스 제공 가능 여부 및 신청 가능시점 등은\\n반드시 Checklist - Checklist Information - Codeshare INFO 확인 또는 [Tools] - [Help&amp;Information] - Topic에서 CODESHARE INFO 선택 - 항공사 조회하여 안내\\n√ FMLY CARE SVC, FRES 등 KE 고유 서비스 신청 불가\\n√ CHML 신청시 메뉴 선택 불가\\n√ 공동운항편은 UM 신청 불가, 운항사의 UM 적용 연령은 상이할수 있으므로 미성년자 예약 시 반드시 확인 요망\\n - 공동운항편에 미성년자 예약시 유의사항 ☞ Click Here\\n☞ 상기와 같은 사유로 고객의 요청 서비스를 제공할수 없는 경우, 정중히 안내 후 대체 가능한 운항편으로 유도\\n○ 공동운항 수하물은 협정에 따라 운항사 또는 판매사 규정이 적용 됨으로 Codeshare Info 내 항공사를 조회하여 안내\\n(단, 수하물 협약사항에는 FRA 및 EBC 규정만 있으므로 협약사항에 없는 스포츠 수하물/악기 등과 같은 특수 수하물은 운항사의 규정을 따름)\\n    </td>\\n   </tr>\\n   <tr>\\n    <td>\\n     Excess Baggage Auth 적용 관련\\n    </td>\\n   </tr>\\n   <tr>\\n    <td>\\n     ○ KE ON-LINE FLT에서 KE Marketing 공동운항편으로 변경 시 Excess Baggage Auth가 있는 경우 혜택 제공 불가\\n단, KE/OK 공동운항편의 경우 Excess Baggage Auth 적용 가능하므로 PNR 내 해당 Auth 확인 요망(Click)\\n    </td>\\n   </tr>\\n  </table><table><img ahref=\"www.google.com\">\"YOUR SOURCE\"</img>Test by Eungi</table>',\n",
    "}\n",
    "\n",
    "\n",
    "def make_data(txt):\n",
    "    soup = BeautifulSoup(txt, \"lxml\")\n",
    "    txt = soup.prettify()\n",
    "    return txt\n",
    "\n",
    "\n",
    "txt = make_data(data[\"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def clean_soup_tags(doc: str) -> str:\n",
    "    pat = re.compile(r\"<.*html>|<*.body>\")\n",
    "    doc = re.sub(pat, \"\", doc)\n",
    "    return doc.strip()\n",
    "\n",
    "\n",
    "def leave_valid_tags(doc: str, valid_tags: list) -> str:\n",
    "    soup = BeautifulSoup(doc, \"lxml\")\n",
    "    for x in soup.find_all():\n",
    "        if len(x.get_text(strip=True)) == 0 and x.name not in valid_tags:\n",
    "            x.extract()\n",
    "    return soup.prettify()\n",
    "\n",
    "\n",
    "valid_tags = [\"p\", \"table\", \"th\", \"tr\", \"td\", \"img\"]\n",
    "txt = leave_valid_tags(txt, valid_tags)\n",
    "txt = clean_soup_tags(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from typing import Tuple, Literal, Optional, List, Any\n",
    "from dataclasses import dataclass, field\n",
    "from uuid import uuid4\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Match:\n",
    "    indice: Tuple[int, int]\n",
    "    \"indice tuple of start_idx and end_idx.\"\n",
    "    match: str\n",
    "    \"matched part\"\n",
    "    metadata: dict = field(default_factory=dict)\n",
    "    \"arbitrary metadata about the match (e.g., source, attributes, relationships to other matches, etc.)\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Tag:\n",
    "    indice: Tuple[int, int]\n",
    "    name: str\n",
    "    child: List[Tag] = field(default_factory=list)\n",
    "    parent: List[Tag] = field(default_factory=list)\n",
    "    metadata: dict = field(default_factory=dict)\n",
    "    \"arbitrary metadata about the page content (e.g., source, attributes, relationships to other matches, etc.)\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Chunk:\n",
    "    indice: Tuple[int, int]\n",
    "    content: str\n",
    "    metadata: dict = field(default_factory=dict)\n",
    "\n",
    "\n",
    "def find_tag_bundle(txt, tag):\n",
    "    tags = []\n",
    "    tag_counter = defaultdict(int)\n",
    "\n",
    "    pat = re.compile(rf\"<.*{tag}>\")\n",
    "    match = pat.search(txt)\n",
    "\n",
    "    matches = []\n",
    "    while match:\n",
    "        # get matched_tag. e.g. <table>, </table>\n",
    "        matched_tag = match.group(0)\n",
    "        # count depth of matched_tag to do pairing later\n",
    "        tag_counter[matched_tag] += 1\n",
    "        depth = tag_counter[matched_tag]\n",
    "        matches += [\n",
    "            Match(indice=match.span(), match=matched_tag, metadata={\"depth\": depth})\n",
    "        ]\n",
    "        # get pair_tag. e.g, <table> -> </table>\n",
    "        pair_matched_tag = (\n",
    "            rf\"</{tag}>\" if r\"/\" not in matched_tag else matched_tag.replace(r\"/\", \"\")\n",
    "        )\n",
    "\n",
    "        # recognize as Tag if depth matches with each other\n",
    "        if depth == tag_counter[pair_matched_tag]:\n",
    "            # pairing matches according to the matching depth\n",
    "            matches = sorted(matches, key=lambda x: x.metadata[\"depth\"])\n",
    "            start, end = matches[0], matches[-1]\n",
    "            indice = start.indice + end.indice\n",
    "            start_idx, end_idx = min(indice), max(indice)\n",
    "            tag_name = start.match\n",
    "            id = str(uuid4())\n",
    "            tags += [\n",
    "                Tag(indice=(start_idx, end_idx), name=tag_name, metadata={\"id\": id})\n",
    "            ]\n",
    "            # reset after chunking done\n",
    "            matches = []\n",
    "            tag_counter[matched_tag], tag_counter[pair_matched_tag] = 0, 0\n",
    "        match = pat.search(txt, match.start() + 1)\n",
    "    return tags\n",
    "\n",
    "\n",
    "def add_relationship_to_tag(tag, tags) -> None:\n",
    "    start, end = tag.indice\n",
    "\n",
    "    parent_cands = []\n",
    "    _tags = [_tag for _tag in tags if _tag != tag and _tag.name != tag.name]\n",
    "    for _tag in _tags:\n",
    "        _start, _end = _tag.indice\n",
    "        if _start < start and _end > end:\n",
    "            parent_cands += [_tag]\n",
    "\n",
    "    # get neareast parent\n",
    "    if len(parent_cands) > 0:\n",
    "        parent = parent_cands[0]\n",
    "        min_gap = abs(parent.indice[0] - start)\n",
    "        for cand in parent_cands:\n",
    "            _gap = abs(cand.indice[0] - start)\n",
    "            if _gap < min_gap:\n",
    "                parent = cand\n",
    "                min_gap = _gap\n",
    "\n",
    "        parent.child += [tag.metadata[\"id\"]]\n",
    "        tag.parent += [parent.metadata[\"id\"]]\n",
    "\n",
    "\n",
    "def get_tag_from_id(id, tags):\n",
    "    for tag in tags:\n",
    "        if id == tag.metadata[\"id\"]:\n",
    "            return tag\n",
    "\n",
    "\n",
    "def update_tags(tags):\n",
    "    for tag in tags:\n",
    "        childs = [get_tag_from_id(id, tags) for id in tag.child]\n",
    "        parents = [get_tag_from_id(id, tags) for id in tag.parent]\n",
    "        childs = sorted(childs, key=lambda x: x.indice[0], reverse=False)\n",
    "        parents = sorted(parents, key=lambda x: x.indice[0], reverse=False)\n",
    "\n",
    "        tag.child = childs\n",
    "        tag.parent = parents\n",
    "\n",
    "\n",
    "def get_no_parent_tags(tags):\n",
    "    _tags = [_tag for _tag in tags if len(_tag.parent) == 0]\n",
    "    _tags = sorted(_tags, key=lambda x: x.indice[0], reverse=False)\n",
    "    return _tags\n",
    "\n",
    "\n",
    "def get_chunks(txt, tags):\n",
    "    start = 0\n",
    "    chunks = []\n",
    "    for tag in tags:\n",
    "        _start, _end = tag.indice\n",
    "        chunks += [Chunk(indice=(start, _start), content=txt[start:_start])]\n",
    "        chunks += [Chunk(indice=(_start, _end), content=txt[_start:_end])]\n",
    "        start = _end\n",
    "    return chunks\n",
    "\n",
    "\n",
    "tags = []\n",
    "for html_tag in [\"table\", \"tr\", \"td\"]:\n",
    "    tags.extend(find_tag_bundle(txt, html_tag))\n",
    "\n",
    "for tag in tags:\n",
    "    add_relationship_to_tag(tag, tags)\n",
    "update_tags(tags)\n",
    "tags = get_no_parent_tags(tags)\n",
    "chunks = get_chunks(txt, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"\".join([chunk.content for chunk in chunks]) == txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
