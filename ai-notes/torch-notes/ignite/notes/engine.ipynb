{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`https://pytorch.org/ignite/concepts.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from ignite.engine import Engine\n",
    "from ignite.engine import Events\n",
    "from ignite.metrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(100, 3)\n",
    "y = torch.rand(100, 1)\n",
    "\n",
    "model = nn.Linear(in_features=3, out_features=1)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "crit = nn.MSELoss()\n",
    "\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class testDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        super().__init__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        y = self.labels[idx]\n",
    "        return x, y\n",
    "\n",
    "\n",
    "indices = torch.randperm(x.size(0))\n",
    "train_cnt = int(x.size(0) * 0.8)\n",
    "valid_cnt = x.size(0) - train_cnt\n",
    "\n",
    "train_x, valid_x = torch.index_select(x, dim=0, index=indices).split(\n",
    "    [train_cnt, valid_cnt], dim=0\n",
    ")\n",
    "\n",
    "train_y, valid_y = torch.index_select(y, dim=0, index=indices).split(\n",
    "    [train_cnt, valid_cnt], dim=0\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=testDataset(train_x, train_y), batch_size=16, shuffle=True\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    dataset=testDataset(train_y, valid_y), batch_size=16, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training.\n",
      "Another message of start training.\n",
      "Epoch: 1, Iteration: 1, Loss: 0.8205951452255249\n",
      "Epoch: 1, Iteration: 2, Loss: 0.8183078169822693\n",
      "Epoch: 1, Iteration: 3, Loss: 0.8641492128372192\n",
      "Epoch: 1, Iteration: 4, Loss: 0.8837684988975525\n",
      "Epoch: 1, Iteration: 5, Loss: 0.9812270402908325\n",
      "Epoch: 2, Iteration: 6, Loss: 0.9132032990455627\n",
      "Epoch: 2, Iteration: 7, Loss: 0.7664456367492676\n",
      "Epoch: 2, Iteration: 8, Loss: 0.8986122012138367\n",
      "Epoch: 2, Iteration: 9, Loss: 0.7346012592315674\n",
      "Epoch: 2, Iteration: 10, Loss: 0.9507958889007568\n",
      "Epoch: 3, Iteration: 11, Loss: 0.8530470132827759\n",
      "Epoch: 3, Iteration: 12, Loss: 0.7313729524612427\n",
      "Epoch: 3, Iteration: 13, Loss: 0.7436090707778931\n",
      "Epoch: 3, Iteration: 14, Loss: 0.9435837268829346\n",
      "Epoch: 3, Iteration: 15, Loss: 0.8863449692726135\n",
      "Epoch: 4, Iteration: 16, Loss: 0.9313111901283264\n",
      "Epoch: 4, Iteration: 17, Loss: 0.7555874586105347\n",
      "Epoch: 4, Iteration: 18, Loss: 0.6950225830078125\n",
      "Epoch: 4, Iteration: 19, Loss: 0.8302692770957947\n",
      "Epoch: 4, Iteration: 20, Loss: 0.8473137617111206\n",
      "Epoch: 5, Iteration: 21, Loss: 0.8376688957214355\n",
      "Epoch: 5, Iteration: 22, Loss: 0.7723775506019592\n",
      "Epoch: 5, Iteration: 23, Loss: 0.8286383152008057\n",
      "Epoch: 5, Iteration: 24, Loss: 0.715936005115509\n",
      "Epoch: 5, Iteration: 25, Loss: 0.8023566603660583\n",
      "Epoch: 6, Iteration: 26, Loss: 0.7573739290237427\n",
      "Epoch: 6, Iteration: 27, Loss: 0.7386834621429443\n",
      "Epoch: 6, Iteration: 28, Loss: 0.7678025960922241\n",
      "Epoch: 6, Iteration: 29, Loss: 0.7659897208213806\n",
      "Epoch: 6, Iteration: 30, Loss: 0.8301073312759399\n",
      "Epoch: 7, Iteration: 31, Loss: 0.8968465328216553\n",
      "Epoch: 7, Iteration: 32, Loss: 0.9562190175056458\n",
      "Epoch: 7, Iteration: 33, Loss: 0.501595139503479\n",
      "Epoch: 7, Iteration: 34, Loss: 0.6152538657188416\n",
      "Epoch: 7, Iteration: 35, Loss: 0.7959133386611938\n",
      "Epoch: 8, Iteration: 36, Loss: 0.729831874370575\n",
      "Epoch: 8, Iteration: 37, Loss: 0.6079672574996948\n",
      "Epoch: 8, Iteration: 38, Loss: 0.7089837789535522\n",
      "Epoch: 8, Iteration: 39, Loss: 0.7315506935119629\n",
      "Epoch: 8, Iteration: 40, Loss: 0.8906942009925842\n",
      "Epoch: 9, Iteration: 41, Loss: 0.6895807385444641\n",
      "Epoch: 9, Iteration: 42, Loss: 0.7481663227081299\n",
      "Epoch: 9, Iteration: 43, Loss: 0.7531261444091797\n",
      "Epoch: 9, Iteration: 44, Loss: 0.7971064448356628\n",
      "Epoch: 9, Iteration: 45, Loss: 0.5912131071090698\n",
      "Epoch: 10, Iteration: 46, Loss: 0.9507617950439453\n",
      "Epoch: 10, Iteration: 47, Loss: 0.6851590871810913\n",
      "Epoch: 10, Iteration: 48, Loss: 0.47677356004714966\n",
      "Epoch: 10, Iteration: 49, Loss: 0.7172974348068237\n",
      "Epoch: 10, Iteration: 50, Loss: 0.658409833908081\n",
      "Training is ended. mydata=[1, 2, 3, 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "State:\n",
       "\titeration: 50\n",
       "\tepoch: 10\n",
       "\tepoch_length: 5\n",
       "\tmax_epochs: 10\n",
       "\toutput: 0.658409833908081\n",
       "\tbatch: <class 'list'>\n",
       "\tmetrics: <class 'dict'>\n",
       "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
       "\tseed: <class 'NoneType'>\n",
       "\ttimes: <class 'dict'>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_step(engine, mini_batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    x, y = mini_batch\n",
    "    y_pred = model(x)\n",
    "    loss = crit(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # The type of output of the training step (i.e. loss.item() in the above example)\n",
    "    # is not restricted. Training step function can return everything user wants.\n",
    "    # Output is set to trainer.state.output and can be used further for any type of processing.\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "train_engine = Engine(train_step)\n",
    "\n",
    "train_engine.add_event_handler(Events.STARTED, lambda _: print(\"Start Training.\"))\n",
    "\n",
    "\n",
    "## OR\n",
    "@train_engine.on(Events.STARTED)\n",
    "def on_training_started(engine):\n",
    "    print(\"Another message of start training.\")\n",
    "\n",
    "\n",
    "def on_iteration_completed(engine):\n",
    "    iteration = engine.state.iteration\n",
    "    epoch = engine.state.epoch\n",
    "    loss = engine.state.output\n",
    "    print(f\"Epoch: {epoch}, Iteration: {iteration}, Loss: {loss}\")\n",
    "\n",
    "\n",
    "train_engine.add_event_handler(Events.ITERATION_COMPLETED, on_iteration_completed)\n",
    "\n",
    "mydata = [1, 2, 3, 4]\n",
    "\n",
    "\n",
    "def on_training_ended(engine, data):\n",
    "    print(f\"Training is ended. mydata={data}\")\n",
    "\n",
    "\n",
    "train_engine.add_event_handler(Events.COMPLETED, on_training_ended, mydata)\n",
    "\n",
    "train_engine.run(train_loader, max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Dec 15 2022, 10:44:50) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "a10b254881f706e42c635ed13e00f86233c557d346dd26ed90d26c2bb04c756e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
