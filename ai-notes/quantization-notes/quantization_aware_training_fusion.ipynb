{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "random_seed = 0\n",
    "num_classes = 10  # CIFAR10 datasets has 10 image classes\n",
    "\n",
    "# Define model file paths\n",
    "model_dir = \"./data\"\n",
    "model_fn = \"resnet18_cifar10.pt\"\n",
    "quantized_model_fn = \"resnet18_quantized_cifar10.pt\"\n",
    "model_file_path = os.path.join(model_dir, model_fn)\n",
    "quantized_model_file_path = os.path.join(model_dir, quantized_model_fn)\n",
    "\n",
    "# Set device\n",
    "device = \"cpu:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get resnet model to train and test\n",
    "model = resnet18(num_classes=num_classes, weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seeds(random_seed=0):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "\n",
    "\n",
    "def prepare_dataloader(num_workers=8, train_batch_size=128, eval_batch_size=256):\n",
    "    train_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    test_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    train_set = torchvision.datasets.CIFAR10(\n",
    "        root=\"data\", train=True, download=True, transform=train_transform\n",
    "    )\n",
    "    # We will use test set for validation and test in this project.\n",
    "    # Do not use test set for validation in practice!\n",
    "    test_set = torchvision.datasets.CIFAR10(\n",
    "        root=\"data\", train=False, download=True, transform=test_transform\n",
    "    )\n",
    "\n",
    "    train_sampler = torch.utils.data.RandomSampler(train_set)\n",
    "    test_sampler = torch.utils.data.SequentialSampler(test_set)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_set,\n",
    "        batch_size=train_batch_size,\n",
    "        sampler=train_sampler,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_set,\n",
    "        batch_size=eval_batch_size,\n",
    "        sampler=test_sampler,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device, criterion=None):\n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "\n",
    "    model.eval()\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        if criterion is not None:\n",
    "            loss = criterion(outputs, labels).item()\n",
    "        else:\n",
    "            loss = 0\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    eval_loss = running_loss / len(test_loader.dataset)\n",
    "    eval_accuracy = running_corrects / len(test_loader.dataset)\n",
    "\n",
    "    return eval_loss, eval_accuracy\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model, train_loader, test_loader, device, learning_rate=1e-1, num_epochs=200\n",
    "):\n",
    "    # The training configurations were not carefully selected.\n",
    "    # Settings below is just to represent the normal training process.\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.to(device)\n",
    "\n",
    "    # It seems that SGD optimizer is better than Adam optimizer for ResNet18 training on CIFAR10.\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-4\n",
    "    )\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=500)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer, milestones=[100, 150], gamma=0.1, last_epoch=-1\n",
    "    )\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "    # Evaluation\n",
    "    eval_loss, eval_accuracy = evaluate_model(\n",
    "        model=model, test_loader=test_loader, device=device, criterion=criterion\n",
    "    )\n",
    "    print(\n",
    "        \"Epoch: {:02d} Eval Loss: {:.3f} Eval Acc: {:.3f}\".format(\n",
    "            -1, eval_loss, eval_accuracy\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0\n",
    "        running_corrects = 0\n",
    "\n",
    "        data_iterator = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "        for inputs, labels in data_iterator:\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)  # |batch_size, num_classes|\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            data_iterator.set_postfix(loss=loss.item())\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_accuracy = running_corrects / len(train_loader.dataset)\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        eval_loss, eval_accuracy = evaluate_model(\n",
    "            model=model, test_loader=test_loader, device=device, criterion=criterion\n",
    "        )\n",
    "\n",
    "        # Set learning rate scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        print(\n",
    "            \"Epoch: {:03d} Train Loss: {:.3f} Train Acc: {:.3f} Eval Loss: {:.3f} Eval Acc: {:.3f}\".format(\n",
    "                epoch, train_loss, train_accuracy, eval_loss, eval_accuracy\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def save_model(model, model_dir, model_filename):\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    model_filepath = os.path.join(model_dir, model_filename)\n",
    "    torch.save(model.state_dict(), model_filepath)\n",
    "\n",
    "\n",
    "# Set random seed\n",
    "set_random_seeds(random_seed=0)\n",
    "\n",
    "# Get train dataset loader and test dataset loader\n",
    "train_loader, test_loader = prepare_dataloader(\n",
    "    num_workers=1, train_batch_size=4, eval_batch_size=8\n",
    ")\n",
    "\n",
    "# Get resnet model to train and test\n",
    "model = resnet18(num_classes=num_classes, weights=None)\n",
    "\n",
    "# Train model\n",
    "model = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    device=device,\n",
    "    learning_rate=1e-1,\n",
    "    num_epochs=10,\n",
    ")\n",
    "\n",
    "# Save model\n",
    "save_model(model=model, model_dir=model_dir, model_filename=model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, model_filepath, device):\n",
    "    model.load_state_dict(torch.load(model_filepath, map_location=device))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_equivalence(\n",
    "    model_1,\n",
    "    model_2,\n",
    "    device,\n",
    "    rtol=1e-05,\n",
    "    atol=1e-08,\n",
    "    num_tests=100,\n",
    "    input_size=(1, 3, 32, 32),\n",
    "):\n",
    "    model_1.to(device)\n",
    "    model_2.to(device)\n",
    "\n",
    "    for _ in range(num_tests):\n",
    "        x = torch.rand(size=input_size).to(device)\n",
    "        y1 = model_1(x).detach().cpu().numpy()\n",
    "        y2 = model_2(x).detach().cpu().numpy()\n",
    "        if np.allclose(a=y1, b=y2, rtol=rtol, atol=atol, equal_nan=False) == False:\n",
    "            print(\"Model equivalence test sample failed: \")\n",
    "            print(y1, y2)\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "# Load pretrained model\n",
    "model = load_model(model, model_file_path, device)\n",
    "\n",
    "# Move the model to CPU since static quantization does not support CUDA currently.\n",
    "model.to(\"cpu:0\")\n",
    "fused_model = copy.deepcopy(model)\n",
    "\n",
    "# Turn on eval() mode to fuse model before training\n",
    "model.eval()\n",
    "fused_model.eval()\n",
    "fused_model = torch.quantization.fuse_modules(\n",
    "    fused_model, [[\"conv1\", \"bn1\", \"relu\"]], inplace=True\n",
    ")\n",
    "for module_name, module in fused_model.named_children():\n",
    "    if \"layer\" in module_name:\n",
    "        for basic_block_name, basic_block in module.named_children():\n",
    "            torch.quantization.fuse_modules(\n",
    "                basic_block, [[\"conv1\", \"bn1\", \"relu1\"], [\"conv2\", \"bn2\"]], inplace=True\n",
    "            )\n",
    "            for sub_block_name, sub_block in basic_block.named_children():\n",
    "                if sub_block_name == \"downsample\":\n",
    "                    torch.quantization.fuse_modules(\n",
    "                        sub_block, [[\"0\", \"1\"]], inplace=True\n",
    "                    )\n",
    "\n",
    "# Check if the results are same\n",
    "assert model_equivalence(\n",
    "    model_1=model,\n",
    "    model_2=fused_model,\n",
    "    device=\"cpu:0\",\n",
    "    rtol=1e-03,\n",
    "    atol=1e-06,\n",
    "    num_tests=100,\n",
    "    input_size=(1, 3, 32, 32),\n",
    "), \"Fused model is not equivalent to the original model!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizedResNet18(nn.Module):\n",
    "    def __init__(self, model_fp32):\n",
    "        super(QuantizedResNet18, self).__init__()\n",
    "        # QuantStub converts tensors from floating point to quantized.\n",
    "        # This will only be used for inputs.\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        # DeQuantStub converts tensors from quantized to floating point.\n",
    "        # This will only be used for outputs.\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "        # FP32 model\n",
    "        self.model_fp32 = model_fp32\n",
    "\n",
    "    def forward(self, x):\n",
    "        # manually specify where tensors will be converted from floating\n",
    "        # point to quantized in the quantized model\n",
    "        x = self.quant(x)\n",
    "        x = self.model_fp32(x)\n",
    "        # manually specify where tensors will be converted from quantized\n",
    "        # to floating point in the quantized model\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Prepare the model for quantization aware training. This inserts observers in\n",
    "# the model that will observe activation tensors during calibration.\n",
    "quantized_model = QuantizedResNet18(model_fp32=fused_model)\n",
    "# Using un-fused model will fail.\n",
    "# Because there is no quantized layer implementation for a single batch normalization layer.\n",
    "# quantized_model = QuantizedResNet18(model_fp32=model)\n",
    "\n",
    "# Select quantization schemes from\n",
    "# https://pytorch.org/docs/stable/quantization-support.html\n",
    "print(torch.backends.quantized.supported_engines)\n",
    "torch.backends.quantized.engine = \"qnnpack\"\n",
    "quantization_config = torch.ao.quantization.default_qconfig\n",
    "# Custom quantization configurations\n",
    "# quantization_config = torch.quantization.default_qconfig\n",
    "# quantization_config = torch.quantization.QConfig(activation=torch.quantization.MinMaxObserver.with_args(dtype=torch.quint8), weight=torch.quantization.MinMaxObserver.with_args(dtype=torch.qint8, qscheme=torch.per_tensor_symmetric))\n",
    "quantized_model.qconfig = quantization_config\n",
    "\n",
    "# Print quantization configurations\n",
    "print(quantized_model.qconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_torchscript_model(model, model_dir, model_filename):\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    model_filepath = os.path.join(model_dir, model_filename)\n",
    "    torch.jit.save(torch.jit.script(model), model_filepath)\n",
    "\n",
    "\n",
    "def load_torchscript_model(model_filepath, device):\n",
    "    model = torch.jit.load(model_filepath, map_location=device)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model(num_classes=10):\n",
    "    # The number of channels in ResNet18 is divisible by 8.\n",
    "    # This is required for fast GEMM integer matrix multiplication.\n",
    "    # model = torchvision.models.resnet18(pretrained=False)\n",
    "    model = resnet18(num_classes=num_classes, pretrained=False)\n",
    "\n",
    "    # We would use the pretrained ResNet18 as a feature extractor.\n",
    "    # for param in model.parameters():\n",
    "    #     param.requires_grad = False\n",
    "\n",
    "    # Modify the last FC layer\n",
    "    # num_features = model.fc.in_features\n",
    "    # model.fc = nn.Linear(num_features, 10)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# https://pytorch.org/docs/stable/_modules/torch/quantization/quantize.html#prepare_qat\n",
    "torch.quantization.prepare_qat(quantized_model, inplace=True)\n",
    "\n",
    "# # Use training data for calibration.\n",
    "print(\"Training QAT Model...\")\n",
    "quantized_model.train()\n",
    "\n",
    "train_model(\n",
    "    model=quantized_model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    device=device,\n",
    "    learning_rate=1e-3,\n",
    "    num_epochs=10,\n",
    ")\n",
    "\n",
    "quantized_model.to(\"cpu:0\")\n",
    "# Using high-level static quantization wrapper\n",
    "# The above steps, including torch.quantization.prepare, calibrate_model, and torch.quantization.convert, are also equivalent to\n",
    "# quantized_model = torch.quantization.quantize_qat(model=quantized_model, run_fn=train_model, run_args=[train_loader, test_loader, cuda_device], mapping=None, inplace=False)\n",
    "# ```\n",
    "# def quantize_qat(model, run_fn, run_args, inplace=False):\n",
    "#     r\"\"\"Do quantization aware training and output a quantized model\n",
    "\n",
    "#     Args:\n",
    "#         model: input model\n",
    "#         run_fn: a function for evaluating the prepared model, can be a\n",
    "#                 function that simply runs the prepared model or a training\n",
    "#                 loop\n",
    "#         run_args: positional arguments for `run_fn`\n",
    "\n",
    "#     Return:\n",
    "#         Quantized model.\n",
    "#     \"\"\"\n",
    "#     torch._C._log_api_usage_once(\"quantization_api.quantize.quantize_qat\")\n",
    "#     if not inplace:\n",
    "#         model = copy.deepcopy(model)\n",
    "#     model.train()\n",
    "#     prepare_qat(model, inplace=True)\n",
    "#     run_fn(model, *run_args)\n",
    "#     convert(model, inplace=True)\n",
    "#     return model\n",
    "# ```\n",
    "\n",
    "quantized_model = torch.quantization.convert(quantized_model, inplace=True)\n",
    "quantized_model.eval()\n",
    "\n",
    "# Print quantized model.\n",
    "print(quantized_model)\n",
    "\n",
    "# Save quantized model.\n",
    "save_torchscript_model(\n",
    "    model=quantized_model, model_dir=model_dir, model_filename=quantized_model_fn\n",
    ")\n",
    "\n",
    "# Load quantized model.\n",
    "quantized_jit_model = load_torchscript_model(\n",
    "    model_filepath=quantized_model_file_path, device=\"cpu:0\"\n",
    ")\n",
    "\n",
    "_, fp32_eval_accuracy = evaluate_model(\n",
    "    model=model, test_loader=test_loader, device=\"cpu:0\", criterion=None\n",
    ")\n",
    "_, int8_eval_accuracy = evaluate_model(\n",
    "    model=quantized_jit_model, test_loader=test_loader, device=\"cpu:0\", criterion=None\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
